import aiohttp
import asyncio
import json
import os
import time
import threading
import shutil

# Persistent memory storage file
MEMORY_FILE = "ai_memory_v5.json"
CODE_UPDATE_FILE = "ai_code_updates_v5.py"
AI_SOURCE_FILE = "ai_system_v5.py"
AI_BACKUP_FILE = "ai_system_backup_v5.py"
AI_LOG_FILE = "ai_performance_log_v5.json"
CACHE_FILE = "ai_cache_v5.json"
API_URL = "http://localhost:8000/generate"
cache = {}

# Load persistent memory
def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r") as file:
            return json.load(file)
    return {}

# Save persistent memory
def save_memory(data):
    with open(MEMORY_FILE, "w") as file:
        json.dump(data, file, indent=4)

# Load persistent cache
def load_cache():
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r") as file:
            return json.load(file)
    return {}

# Save persistent cache
def save_cache(data):
    with open(CACHE_FILE, "w") as file:
        json.dump(data, file, indent=4)

cache = load_cache()

# Save performance logs
def log_performance(data):
    with open(AI_LOG_FILE, "a") as file:
        json.dump(data, file, indent=4)
        file.write("\n")

# Asynchronous API request with caching
async def generate_text(prompt, timeout=None):
    try:
        if prompt in cache and time.time() - cache[prompt]['timestamp'] < 600:
            return cache[prompt]['response']
        
        # Adjust timeout dynamically based on past response times
        avg_response_time = cache.get("avg_response_time", 90)
        timeout = timeout or min(max(60, avg_response_time * 1.5), 180)

        headers = {"Content-Type": "application/json"}
        data = {"prompt": prompt}

        async with aiohttp.ClientSession() as session:
            for attempt in range(3):
                async with session.post(API_URL, json=data, headers=headers, timeout=timeout) as response:
                    if response.status == 200:
                        response_json = await response.json()
                        response_time = time.time() - cache.get("last_api_call", time.time())
                        cache["last_api_call"] = time.time()
                        cache["avg_response_time"] = (cache.get("avg_response_time", response_time) + response_time) / 2  # Update average response time
                        cache[prompt] = {'response': response_json.get("response", "[No response received]"), 'timestamp': time.time()}
                        save_cache(cache)
                        return response_json.get("response", "[No response received]")
                    print(f"âš ï¸ API request failed (Attempt {attempt + 1}/3). Retrying...")
                    await asyncio.sleep(5)
        return "[Error: API request failed after 3 attempts]"
    except (aiohttp.ClientError, asyncio.TimeoutError) as e:
        print(f"ðŸš¨ API Error: {e}")
        return "[Error: API request timed out or failed]"
    except Exception as e:
        print(f"ðŸš¨ Unexpected Error in generate_text: {e}")
        return "[Error: Unexpected issue occurred]"

# AI Self-Improvement with Reinforcement Learning & Meta-Learning
async def auto_improve():
    print("ðŸ”„ AI is self-improving...")
    memory = load_memory()
    prompt = "Step 1: Identify a novel AI optimization. Do NOT repeat past improvements unless necessary. Prioritize impactful refinements."
    improvement = await generate_text(prompt)
    
    past_improvements = memory.get("past_improvements", [])
    if improvement.strip() and (improvement not in past_improvements or len(past_improvements) < 5):
        memory.setdefault("past_improvements", []).append(improvement)
        memory["last_improvement"] = {"timestamp": time.ctime(), "change": improvement.strip()}
        save_memory(memory)
        log_performance(memory["last_improvement"])
        print("âœ… AI improvement complete!")
    else:
        print("âš ï¸ AI failed to generate a meaningful improvement. Requesting alternative approach...")
        improvement = await generate_text("Generate a completely new AI optimization strategy.")
        if improvement.strip():
            memory["last_improvement"] = {"timestamp": time.ctime(), "change": improvement.strip()}
            save_memory(memory)
            log_performance(memory["last_improvement"])
            print("âœ… AI alternative improvement applied!")

# Continuous AI Learning with Optimized Speed Adaptation
async def continuous_learning():
    interval = 120
    while True:
        try:
            await auto_improve()
            interval = max(45, min(interval * 0.9, 900))  # Adjusted for stable learning speed
            print(f"ðŸ” AI has completed a cycle. Next cycle in {interval:.0f} seconds.")
        except Exception as e:
            print(f"ðŸš¨ Error encountered: {str(e)}. Slowing down to prevent instability.")
            interval = min(1800, interval * 1.5)
        await asyncio.sleep(interval)

def start_ai():
    print("ðŸš€ AI is now running in autonomous mode...")
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(continuous_learning())
    
if __name__ == "__main__":
    start_ai()
